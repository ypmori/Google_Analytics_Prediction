{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3: Initial Model Development and Analysis\n",
    "\n",
    "##### Author: Yuji Mori\n",
    "##### Last Updated: 02/10/2021\n",
    "\n",
    "Tasks:\n",
    "- Perform feature engineering\n",
    "- Estimate 1 (baseline) model and evaluate model performance\n",
    "- Hint: Determine what metric(s) is/are appropriate for your use case\n",
    "- Estimate 1 (different) model and/or loss function to improve model performance\n",
    "- Interpret results of model\n",
    "- Use results to answer business question you posed\n",
    "- Write-up a summary of what you did and why in “Methodology” section of README, referencing 3+ cells, figures and/or tables \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON flattening code\n",
    "# This code was widely used by most Kaggle competitiors due to JSON structure of some fields\n",
    "# credit goes to:\n",
    "# https://www.kaggle.com/julian3833/1-quick-start-read-csv-and-flatten-json-fields\n",
    "\n",
    "def load_df(csv_path='../data/train.csv', nrows=None):\n",
    "    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "    df = pd.read_csv(csv_path, \n",
    "                     converters={column: json.loads for column in JSON_COLUMNS}, \n",
    "                     dtype={'fullVisitorId': 'str'}, # Important!!\n",
    "                     nrows=nrows)\n",
    "    \n",
    "    for column in JSON_COLUMNS:\n",
    "        column_as_df = json_normalize(df[column])\n",
    "        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n",
    "        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n",
    "    print(f\"Loaded {os.path.basename(csv_path)}. Shape: {df.shape}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** The Kaggle competition supplies a training and testing set. However, the supplied testing set does not contain the target variable. Therefore, I will use the competition 'training set' and split further into training and testing sets for the purposes of this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-043f74f4a0b7>:14: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "  column_as_df = json_normalize(df[column])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train.csv. Shape: (903653, 55)\n"
     ]
    }
   ],
   "source": [
    "train_df = load_df(csv_path='../data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping Columns\n",
    "\n",
    "We drop some columns that are uninformative for analysis. This includes: \n",
    "\n",
    "- columns without unique values\n",
    "- ID/string columns with only unique values \n",
    "- timestamp columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns without unique values:\n",
    "nunique_cols = [col for col in train_df.columns if train_df[col].nunique() == 1]\n",
    "train_df.drop(nunique_cols, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping string/ID columns that are uninformative or irrelevant for statistical analysis:\n",
    "# - sessionId\n",
    "# - visitId\n",
    "# - fullvisitorID (TEMPORARY -- might aggregate later)\n",
    "# - visitStartTime\n",
    "# - trafficSource.keyword: The keyword of the traffic source\n",
    "# - trafficSource.referralPath: referral URL (if available)\n",
    "# - trafficSource.adwordsClickInfo.gclId: google click ID\n",
    "# - networkDomain: name of ISP provider\n",
    "string_cols = ['sessionId','visitId','fullVisitorId','visitStartTime','trafficSource.keyword', 'trafficSource.referralPath',\n",
    "               'trafficSource.adwordsClickInfo.gclId', 'geoNetwork.networkDomain']\n",
    "train_df.drop(string_cols, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(903653, 23)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling NAs (for numeric columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['totals.transactionRevenue'] = train_df['totals.transactionRevenue'].fillna(0)\n",
    "train_df['totals.pageviews'] = train_df['totals.pageviews'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once NaNs are filled, we can convert to int/float:\n",
    "train_df = train_df.astype({'totals.hits': 'int64', \n",
    "                            'totals.pageviews': 'int64',\n",
    "                            'totals.transactionRevenue':'float'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "channelGrouping                                  object\n",
       "date                                              int64\n",
       "visitNumber                                       int64\n",
       "device.browser                                   object\n",
       "device.operatingSystem                           object\n",
       "device.isMobile                                    bool\n",
       "device.deviceCategory                            object\n",
       "geoNetwork.continent                             object\n",
       "geoNetwork.subContinent                          object\n",
       "geoNetwork.country                               object\n",
       "geoNetwork.region                                object\n",
       "geoNetwork.metro                                 object\n",
       "geoNetwork.city                                  object\n",
       "totals.hits                                       int64\n",
       "totals.pageviews                                  int64\n",
       "totals.transactionRevenue                       float64\n",
       "trafficSource.campaign                           object\n",
       "trafficSource.source                             object\n",
       "trafficSource.medium                             object\n",
       "trafficSource.adwordsClickInfo.page              object\n",
       "trafficSource.adwordsClickInfo.slot              object\n",
       "trafficSource.adwordsClickInfo.adNetworkType     object\n",
       "trafficSource.adContent                          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "\n",
    "#### Grouping low-frequency categories\n",
    "\n",
    "I arbitrarily set a threshold of 100 for all categorical columns. This will help reduce the computational/memory load when dummy encoding.\n",
    "\n",
    "I am adapting code that I found here: https://stackoverflow.com/questions/41577468/replace-low-frequency-categorical-values-from-pandas-dataframe-while-ignoring-na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.apply(lambda x: x.mask(x.map(x.value_counts())<100, 'Other') if x.dtypes == 'O' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channelGrouping</th>\n",
       "      <th>date</th>\n",
       "      <th>visitNumber</th>\n",
       "      <th>device.browser</th>\n",
       "      <th>device.operatingSystem</th>\n",
       "      <th>device.isMobile</th>\n",
       "      <th>device.deviceCategory</th>\n",
       "      <th>geoNetwork.continent</th>\n",
       "      <th>geoNetwork.subContinent</th>\n",
       "      <th>geoNetwork.country</th>\n",
       "      <th>...</th>\n",
       "      <th>totals.hits</th>\n",
       "      <th>totals.pageviews</th>\n",
       "      <th>totals.transactionRevenue</th>\n",
       "      <th>trafficSource.campaign</th>\n",
       "      <th>trafficSource.source</th>\n",
       "      <th>trafficSource.medium</th>\n",
       "      <th>trafficSource.adwordsClickInfo.page</th>\n",
       "      <th>trafficSource.adwordsClickInfo.slot</th>\n",
       "      <th>trafficSource.adwordsClickInfo.adNetworkType</th>\n",
       "      <th>trafficSource.adContent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Organic Search</td>\n",
       "      <td>20160902</td>\n",
       "      <td>1</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Windows</td>\n",
       "      <td>False</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>google</td>\n",
       "      <td>organic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Organic Search</td>\n",
       "      <td>20160902</td>\n",
       "      <td>1</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Macintosh</td>\n",
       "      <td>False</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Australasia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>google</td>\n",
       "      <td>organic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Organic Search</td>\n",
       "      <td>20160902</td>\n",
       "      <td>1</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Windows</td>\n",
       "      <td>False</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Southern Europe</td>\n",
       "      <td>Spain</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>google</td>\n",
       "      <td>organic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Organic Search</td>\n",
       "      <td>20160902</td>\n",
       "      <td>1</td>\n",
       "      <td>UC Browser</td>\n",
       "      <td>Linux</td>\n",
       "      <td>False</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Southeast Asia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>google</td>\n",
       "      <td>organic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Organic Search</td>\n",
       "      <td>20160902</td>\n",
       "      <td>2</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Android</td>\n",
       "      <td>True</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Northern Europe</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>google</td>\n",
       "      <td>organic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  channelGrouping      date  visitNumber device.browser  \\\n",
       "0  Organic Search  20160902            1         Chrome   \n",
       "1  Organic Search  20160902            1        Firefox   \n",
       "2  Organic Search  20160902            1         Chrome   \n",
       "3  Organic Search  20160902            1     UC Browser   \n",
       "4  Organic Search  20160902            2         Chrome   \n",
       "\n",
       "  device.operatingSystem  device.isMobile device.deviceCategory  \\\n",
       "0                Windows            False               desktop   \n",
       "1              Macintosh            False               desktop   \n",
       "2                Windows            False               desktop   \n",
       "3                  Linux            False               desktop   \n",
       "4                Android             True                mobile   \n",
       "\n",
       "  geoNetwork.continent geoNetwork.subContinent geoNetwork.country  ...  \\\n",
       "0                 Asia            Western Asia             Turkey  ...   \n",
       "1              Oceania             Australasia          Australia  ...   \n",
       "2               Europe         Southern Europe              Spain  ...   \n",
       "3                 Asia          Southeast Asia          Indonesia  ...   \n",
       "4               Europe         Northern Europe     United Kingdom  ...   \n",
       "\n",
       "  totals.hits totals.pageviews totals.transactionRevenue  \\\n",
       "0           1                1                       0.0   \n",
       "1           1                1                       0.0   \n",
       "2           1                1                       0.0   \n",
       "3           1                1                       0.0   \n",
       "4           1                1                       0.0   \n",
       "\n",
       "   trafficSource.campaign  trafficSource.source  trafficSource.medium  \\\n",
       "0               (not set)                google               organic   \n",
       "1               (not set)                google               organic   \n",
       "2               (not set)                google               organic   \n",
       "3               (not set)                google               organic   \n",
       "4               (not set)                google               organic   \n",
       "\n",
       "  trafficSource.adwordsClickInfo.page trafficSource.adwordsClickInfo.slot  \\\n",
       "0                                 NaN                                 NaN   \n",
       "1                                 NaN                                 NaN   \n",
       "2                                 NaN                                 NaN   \n",
       "3                                 NaN                                 NaN   \n",
       "4                                 NaN                                 NaN   \n",
       "\n",
       "  trafficSource.adwordsClickInfo.adNetworkType trafficSource.adContent  \n",
       "0                                          NaN                     NaN  \n",
       "1                                          NaN                     NaN  \n",
       "2                                          NaN                     NaN  \n",
       "3                                          NaN                     NaN  \n",
       "4                                          NaN                     NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# Statistical Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I log-transform the revenue from each visit as the response variable:\n",
    "\n",
    "$$ln(totals.transactionRevenue + 1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Log_Revenue'] = np.log(train_df['totals.transactionRevenue'] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary ouputs below demonstrate how the transformation affects the response variable distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    903653.000000\n",
       "mean          0.227118\n",
       "std           2.003710\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.000000\n",
       "75%           0.000000\n",
       "max          23.864375\n",
       "Name: Log_Revenue, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Log_Revenue'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9.036530e+05\n",
       "mean     1.704273e+06\n",
       "std      5.277866e+07\n",
       "min      0.000000e+00\n",
       "25%      0.000000e+00\n",
       "50%      0.000000e+00\n",
       "75%      0.000000e+00\n",
       "max      2.312950e+10\n",
       "Name: totals.transactionRevenue, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['totals.transactionRevenue'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy encode categorical (object dtype) columns using Pandas get_dummies()\n",
    "# dummy_na=True: parameter creates extra column to represent NaN (no need to impute/fill!)\n",
    "\n",
    "train_df_dummies = pd.get_dummies(train_df, dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'visitNumber', 'device.isMobile', 'totals.hits',\n",
       "       'totals.pageviews', 'totals.transactionRevenue', 'Log_Revenue',\n",
       "       'channelGrouping_(Other)', 'channelGrouping_Affiliates',\n",
       "       'channelGrouping_Direct',\n",
       "       ...\n",
       "       'trafficSource.adContent_Ad from 12/13/16',\n",
       "       'trafficSource.adContent_Display Ad created 3/11/14',\n",
       "       'trafficSource.adContent_Display Ad created 3/11/15',\n",
       "       'trafficSource.adContent_Full auto ad IMAGE ONLY',\n",
       "       'trafficSource.adContent_Google Merchandise Collection',\n",
       "       'trafficSource.adContent_Google Online Store',\n",
       "       'trafficSource.adContent_Other',\n",
       "       'trafficSource.adContent_{KeyWord:Google Brand Items}',\n",
       "       'trafficSource.adContent_{KeyWord:Google Merchandise}',\n",
       "       'trafficSource.adContent_nan'],\n",
       "      dtype='object', length=697)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_dummies.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "Aside: \n",
    "\n",
    "I attempted to build a classification model on the `Purchase_Flag` column, but due to some potential leakage, I found that the predictions were perfect. Therefore, I will no longer consider a binary classification model and focus on the initial task of predicting log revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_df['Purchase_Flag'] = train_df['totals.transactionRevenue'] > 0\\ntrain_df['Purchase_Flag'].value_counts()\\n\\ny = train_df_dummies['Purchase_Flag']\\nX = train_df_dummies.drop(['Purchase_Flag','Log_Revenue','totals.transactionRevenue'],axis=1)\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\\n\\ntree_class = tree.DecisionTreeClassifier(max_depth=5)\\ntree_class.fit(X_train, y_train)\\nyhat_tree_class = tree_class.predict(X_test)\\nmetrics.confusion_matrix(y_test, yhat_tree_class)\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREATING A BINARY RESPONSE VARIABLE: IF transactionRevenue > 0, THEN TRUE:\n",
    "'''\n",
    "train_df['Purchase_Flag'] = train_df['totals.transactionRevenue'] > 0\n",
    "train_df['Purchase_Flag'].value_counts()\n",
    "\n",
    "y = train_df_dummies['Purchase_Flag']\n",
    "X = train_df_dummies.drop(['Purchase_Flag','Log_Revenue','totals.transactionRevenue'],axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "tree_class = tree.DecisionTreeClassifier(max_depth=5)\n",
    "tree_class.fit(X_train, y_train)\n",
    "yhat_tree_class = tree_class.predict(X_test)\n",
    "metrics.confusion_matrix(y_test, yhat_tree_class)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "### Model 1 - Single Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = train_df['totals.transactionRevenue']\n",
    "# X = train_df.drop(['totals.transactionRevenue'],axis=1)\n",
    "\n",
    "# WORKING WITH SUBSET FOR NOW:\n",
    "y = train_df_dummies['Log_Revenue']\n",
    "X = train_df_dummies.drop(['Log_Revenue','totals.transactionRevenue'],axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_reg = tree.DecisionTreeRegressor(max_depth=5)\n",
    "tree_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_tree_reg = tree_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9018251720330057"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_squared_error(y_test, yhat_tree_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170.00662721243324"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_squared_error(y_test[y_test > 0], yhat_tree_reg[y_test > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2520814461354193.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_squared_error(np.exp(y_test)-1, np.exp(yhat_tree_reg)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Model 2 -  Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=5, n_estimators=10, random_state=42)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor(n_estimators=10, max_depth=5,random_state=42)\n",
    "rf_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_rf_reg = rf_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.847952847241284"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_squared_error(y_test, yhat_rf_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169.2510254881451"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_squared_error(y_test[y_test > 0], yhat_rf_reg[y_test > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2520901591122565.5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_squared_error(np.exp(y_test)-1, np.exp(yhat_rf_reg)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Regression Tree</th>\n",
       "      <th>Random Forest Regressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE of Log(Revenue)</th>\n",
       "      <td>2.901825e+00</td>\n",
       "      <td>2.847953e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE where Log(Revenue)&gt;0</th>\n",
       "      <td>1.700066e+02</td>\n",
       "      <td>1.692510e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE of Revenue</th>\n",
       "      <td>2.520902e+15</td>\n",
       "      <td>2.520902e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Regression Tree  Random Forest Regressor\n",
       "MSE of Log(Revenue)          2.901825e+00             2.847953e+00\n",
       "MSE where Log(Revenue)>0     1.700066e+02             1.692510e+02\n",
       "MSE of Revenue               2.520902e+15             2.520902e+15"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_dict = {'Regression Tree' : \n",
    "            [metrics.mean_squared_error(y_test, yhat_tree_reg),\n",
    "             metrics.mean_squared_error(y_test[y_test > 0], yhat_tree_reg[y_test > 0]),\n",
    "             metrics.mean_squared_error(np.exp(y_test)-1, np.exp(yhat_rf_reg)-1)],\n",
    "            'Random Forest Regressor':\n",
    "            [metrics.mean_squared_error(y_test, yhat_rf_reg),\n",
    "             metrics.mean_squared_error(y_test[y_test > 0], yhat_rf_reg[y_test > 0]),\n",
    "             metrics.mean_squared_error(np.exp(y_test)-1, np.exp(yhat_rf_reg)-1)\n",
    "            ]\n",
    "           }\n",
    "mse_table = pd.DataFrame(mse_dict, \n",
    "                         index = ['MSE of Log(Revenue)','MSE where Log(Revenue)>0','MSE of Revenue'],\n",
    "                        )\n",
    "\n",
    "mse_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top feature in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'totals.pageviews'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_dummies.columns[np.argmax(rf_reg.feature_importances_)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
